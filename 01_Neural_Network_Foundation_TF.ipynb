{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nasarinagasunil/DeepLearning_with_Tensforflow/blob/main/01_Neural_Network_Foundation_TF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0lxh3z4WoeN",
        "outputId": "865cd23f-8b2f-4809-b8ae-ee4d4acba772"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "NB_CLASSES = 10\n",
        "RESHAPED = 784\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(keras.layers.Dense(NB_CLASSES,\n",
        "            input_shape=(RESHAPED,), kernel_initializer='zeros',\n",
        "            name='dense_layer', activation='softmax'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WHu0_KvXCOr",
        "outputId": "46bbd33f-1716-4a96-8883-849ac1810b9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "# Network and training parameters.\n",
        "EPOCHS = 200\n",
        "BATCH_SIZE = 128\n",
        "VERBOSE = 1\n",
        "NB_CLASSES = 10   # number of outputs = number of digits\n",
        "N_HIDDEN = 128\n",
        "VALIDATION_SPLIT = 0.2 # how much TRAIN is reserved for VALIDATION\n",
        "# Loading MNIST dataset.\n",
        "# verify\n",
        "# You can verify that the split between train and test is 60,000, and 10,000 respectively.\n",
        "# Labels have one-hot representation.is automatically applied\n",
        "mnist = keras.datasets.mnist\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
        "# X_train is 60000 rows of 28x28 values; we  --> reshape it to 60000 x 784.\n",
        "RESHAPED = 784\n",
        "#\n",
        "X_train = X_train.reshape(60000, RESHAPED)\n",
        "X_test = X_test.reshape(10000, RESHAPED)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "# Normalize inputs to be within in [0, 1].\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "# One-hot representation of the labels.\n",
        "Y_train = tf.keras.utils.to_categorical(Y_train, NB_CLASSES)\n",
        "Y_test = tf.keras.utils.to_categorical(Y_test, NB_CLASSES)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DmIqQM-smSRD"
      },
      "outputs": [],
      "source": [
        "# Build the model.\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(keras.layers.Dense(NB_CLASSES,\n",
        "            input_shape=(RESHAPED,),\n",
        "            name='dense_layer',\n",
        "            activation='softmax'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3xvMT3Y6oPmH"
      },
      "outputs": [],
      "source": [
        "# Compiling the model.\n",
        "model.compile(optimizer='SGD',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzESij0LruQ1",
        "outputId": "a4cffdb8-6c75-4dc7-8475-c592bdda5795"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4895 - loss: 1.7713 - val_accuracy: 0.8291 - val_loss: 0.8954\n",
            "Epoch 2/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8214 - loss: 0.8534 - val_accuracy: 0.8605 - val_loss: 0.6552\n",
            "Epoch 3/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8488 - loss: 0.6617 - val_accuracy: 0.8725 - val_loss: 0.5593\n",
            "Epoch 4/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8574 - loss: 0.5848 - val_accuracy: 0.8790 - val_loss: 0.5069\n",
            "Epoch 5/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8659 - loss: 0.5375 - val_accuracy: 0.8847 - val_loss: 0.4727\n",
            "Epoch 6/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8745 - loss: 0.4960 - val_accuracy: 0.8876 - val_loss: 0.4488\n",
            "Epoch 7/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8786 - loss: 0.4757 - val_accuracy: 0.8909 - val_loss: 0.4306\n",
            "Epoch 8/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8788 - loss: 0.4622 - val_accuracy: 0.8948 - val_loss: 0.4165\n",
            "Epoch 9/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8834 - loss: 0.4467 - val_accuracy: 0.8960 - val_loss: 0.4050\n",
            "Epoch 10/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8843 - loss: 0.4336 - val_accuracy: 0.8978 - val_loss: 0.3955\n",
            "Epoch 11/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8859 - loss: 0.4222 - val_accuracy: 0.8983 - val_loss: 0.3877\n",
            "Epoch 12/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8902 - loss: 0.4115 - val_accuracy: 0.8993 - val_loss: 0.3807\n",
            "Epoch 13/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8887 - loss: 0.4124 - val_accuracy: 0.8997 - val_loss: 0.3747\n",
            "Epoch 14/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8918 - loss: 0.3996 - val_accuracy: 0.9003 - val_loss: 0.3695\n",
            "Epoch 15/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8931 - loss: 0.3946 - val_accuracy: 0.9022 - val_loss: 0.3646\n",
            "Epoch 16/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8926 - loss: 0.3927 - val_accuracy: 0.9029 - val_loss: 0.3604\n",
            "Epoch 17/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8948 - loss: 0.3827 - val_accuracy: 0.9038 - val_loss: 0.3566\n",
            "Epoch 18/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8972 - loss: 0.3769 - val_accuracy: 0.9046 - val_loss: 0.3532\n",
            "Epoch 19/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8989 - loss: 0.3730 - val_accuracy: 0.9060 - val_loss: 0.3499\n",
            "Epoch 20/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8993 - loss: 0.3702 - val_accuracy: 0.9068 - val_loss: 0.3469\n",
            "Epoch 21/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9006 - loss: 0.3678 - val_accuracy: 0.9078 - val_loss: 0.3442\n",
            "Epoch 22/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8997 - loss: 0.3641 - val_accuracy: 0.9074 - val_loss: 0.3419\n",
            "Epoch 23/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8999 - loss: 0.3648 - val_accuracy: 0.9087 - val_loss: 0.3393\n",
            "Epoch 24/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9016 - loss: 0.3629 - val_accuracy: 0.9089 - val_loss: 0.3371\n",
            "Epoch 25/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9026 - loss: 0.3500 - val_accuracy: 0.9090 - val_loss: 0.3351\n",
            "Epoch 26/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9015 - loss: 0.3563 - val_accuracy: 0.9093 - val_loss: 0.3332\n",
            "Epoch 27/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9020 - loss: 0.3547 - val_accuracy: 0.9094 - val_loss: 0.3313\n",
            "Epoch 28/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9014 - loss: 0.3528 - val_accuracy: 0.9100 - val_loss: 0.3297\n",
            "Epoch 29/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9029 - loss: 0.3471 - val_accuracy: 0.9102 - val_loss: 0.3281\n",
            "Epoch 30/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9042 - loss: 0.3459 - val_accuracy: 0.9106 - val_loss: 0.3266\n",
            "Epoch 31/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9033 - loss: 0.3469 - val_accuracy: 0.9107 - val_loss: 0.3251\n",
            "Epoch 32/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9056 - loss: 0.3429 - val_accuracy: 0.9106 - val_loss: 0.3237\n",
            "Epoch 33/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9063 - loss: 0.3362 - val_accuracy: 0.9118 - val_loss: 0.3223\n",
            "Epoch 34/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9040 - loss: 0.3398 - val_accuracy: 0.9118 - val_loss: 0.3212\n",
            "Epoch 35/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9049 - loss: 0.3395 - val_accuracy: 0.9111 - val_loss: 0.3200\n",
            "Epoch 36/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9043 - loss: 0.3394 - val_accuracy: 0.9124 - val_loss: 0.3188\n",
            "Epoch 37/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9052 - loss: 0.3359 - val_accuracy: 0.9131 - val_loss: 0.3176\n",
            "Epoch 38/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9079 - loss: 0.3345 - val_accuracy: 0.9128 - val_loss: 0.3167\n",
            "Epoch 39/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9055 - loss: 0.3355 - val_accuracy: 0.9130 - val_loss: 0.3157\n",
            "Epoch 40/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9078 - loss: 0.3257 - val_accuracy: 0.9134 - val_loss: 0.3146\n",
            "Epoch 41/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9089 - loss: 0.3285 - val_accuracy: 0.9141 - val_loss: 0.3137\n",
            "Epoch 42/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9108 - loss: 0.3235 - val_accuracy: 0.9137 - val_loss: 0.3128\n",
            "Epoch 43/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9087 - loss: 0.3283 - val_accuracy: 0.9141 - val_loss: 0.3119\n",
            "Epoch 44/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9087 - loss: 0.3270 - val_accuracy: 0.9146 - val_loss: 0.3111\n",
            "Epoch 45/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9057 - loss: 0.3329 - val_accuracy: 0.9141 - val_loss: 0.3103\n",
            "Epoch 46/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9098 - loss: 0.3200 - val_accuracy: 0.9147 - val_loss: 0.3096\n",
            "Epoch 47/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9100 - loss: 0.3269 - val_accuracy: 0.9150 - val_loss: 0.3089\n",
            "Epoch 48/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9100 - loss: 0.3228 - val_accuracy: 0.9153 - val_loss: 0.3081\n",
            "Epoch 49/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9118 - loss: 0.3188 - val_accuracy: 0.9153 - val_loss: 0.3073\n",
            "Epoch 50/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9097 - loss: 0.3214 - val_accuracy: 0.9155 - val_loss: 0.3066\n",
            "Epoch 51/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9097 - loss: 0.3214 - val_accuracy: 0.9159 - val_loss: 0.3060\n",
            "Epoch 52/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9097 - loss: 0.3264 - val_accuracy: 0.9155 - val_loss: 0.3053\n",
            "Epoch 53/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9115 - loss: 0.3153 - val_accuracy: 0.9161 - val_loss: 0.3047\n",
            "Epoch 54/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9127 - loss: 0.3167 - val_accuracy: 0.9157 - val_loss: 0.3041\n",
            "Epoch 55/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9112 - loss: 0.3189 - val_accuracy: 0.9160 - val_loss: 0.3035\n",
            "Epoch 56/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9135 - loss: 0.3128 - val_accuracy: 0.9162 - val_loss: 0.3030\n",
            "Epoch 57/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9119 - loss: 0.3166 - val_accuracy: 0.9163 - val_loss: 0.3024\n",
            "Epoch 58/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9114 - loss: 0.3194 - val_accuracy: 0.9168 - val_loss: 0.3019\n",
            "Epoch 59/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9115 - loss: 0.3195 - val_accuracy: 0.9169 - val_loss: 0.3013\n",
            "Epoch 60/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9132 - loss: 0.3145 - val_accuracy: 0.9172 - val_loss: 0.3008\n",
            "Epoch 61/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9140 - loss: 0.3125 - val_accuracy: 0.9172 - val_loss: 0.3003\n",
            "Epoch 62/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9148 - loss: 0.3123 - val_accuracy: 0.9176 - val_loss: 0.2997\n",
            "Epoch 63/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9139 - loss: 0.3127 - val_accuracy: 0.9178 - val_loss: 0.2993\n",
            "Epoch 64/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9168 - loss: 0.3048 - val_accuracy: 0.9178 - val_loss: 0.2988\n",
            "Epoch 65/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9129 - loss: 0.3156 - val_accuracy: 0.9180 - val_loss: 0.2984\n",
            "Epoch 66/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9156 - loss: 0.3119 - val_accuracy: 0.9180 - val_loss: 0.2980\n",
            "Epoch 67/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9157 - loss: 0.3075 - val_accuracy: 0.9179 - val_loss: 0.2975\n",
            "Epoch 68/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9141 - loss: 0.3076 - val_accuracy: 0.9181 - val_loss: 0.2971\n",
            "Epoch 69/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9155 - loss: 0.3062 - val_accuracy: 0.9179 - val_loss: 0.2967\n",
            "Epoch 70/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9139 - loss: 0.3105 - val_accuracy: 0.9184 - val_loss: 0.2963\n",
            "Epoch 71/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9147 - loss: 0.3018 - val_accuracy: 0.9183 - val_loss: 0.2959\n",
            "Epoch 72/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9165 - loss: 0.3011 - val_accuracy: 0.9183 - val_loss: 0.2956\n",
            "Epoch 73/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9153 - loss: 0.3058 - val_accuracy: 0.9183 - val_loss: 0.2952\n",
            "Epoch 74/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9164 - loss: 0.2979 - val_accuracy: 0.9187 - val_loss: 0.2949\n",
            "Epoch 75/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9133 - loss: 0.3092 - val_accuracy: 0.9183 - val_loss: 0.2945\n",
            "Epoch 76/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9159 - loss: 0.3032 - val_accuracy: 0.9188 - val_loss: 0.2941\n",
            "Epoch 77/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9154 - loss: 0.3066 - val_accuracy: 0.9194 - val_loss: 0.2937\n",
            "Epoch 78/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9138 - loss: 0.3093 - val_accuracy: 0.9188 - val_loss: 0.2935\n",
            "Epoch 79/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9150 - loss: 0.3051 - val_accuracy: 0.9191 - val_loss: 0.2930\n",
            "Epoch 80/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9174 - loss: 0.3003 - val_accuracy: 0.9193 - val_loss: 0.2928\n",
            "Epoch 81/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9169 - loss: 0.3025 - val_accuracy: 0.9191 - val_loss: 0.2924\n",
            "Epoch 82/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9131 - loss: 0.3077 - val_accuracy: 0.9192 - val_loss: 0.2922\n",
            "Epoch 83/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9167 - loss: 0.2998 - val_accuracy: 0.9192 - val_loss: 0.2918\n",
            "Epoch 84/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9152 - loss: 0.3011 - val_accuracy: 0.9192 - val_loss: 0.2916\n",
            "Epoch 85/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9173 - loss: 0.2958 - val_accuracy: 0.9196 - val_loss: 0.2913\n",
            "Epoch 86/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9151 - loss: 0.2990 - val_accuracy: 0.9188 - val_loss: 0.2910\n",
            "Epoch 87/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9169 - loss: 0.3040 - val_accuracy: 0.9191 - val_loss: 0.2908\n",
            "Epoch 88/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9178 - loss: 0.2979 - val_accuracy: 0.9193 - val_loss: 0.2904\n",
            "Epoch 89/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9154 - loss: 0.3025 - val_accuracy: 0.9199 - val_loss: 0.2901\n",
            "Epoch 90/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9179 - loss: 0.2936 - val_accuracy: 0.9202 - val_loss: 0.2898\n",
            "Epoch 91/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9170 - loss: 0.2964 - val_accuracy: 0.9193 - val_loss: 0.2896\n",
            "Epoch 92/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9170 - loss: 0.2955 - val_accuracy: 0.9204 - val_loss: 0.2893\n",
            "Epoch 93/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9180 - loss: 0.2975 - val_accuracy: 0.9199 - val_loss: 0.2891\n",
            "Epoch 94/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9164 - loss: 0.3022 - val_accuracy: 0.9198 - val_loss: 0.2888\n",
            "Epoch 95/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9179 - loss: 0.2928 - val_accuracy: 0.9202 - val_loss: 0.2887\n",
            "Epoch 96/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9168 - loss: 0.2991 - val_accuracy: 0.9197 - val_loss: 0.2883\n",
            "Epoch 97/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9178 - loss: 0.2921 - val_accuracy: 0.9202 - val_loss: 0.2881\n",
            "Epoch 98/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9185 - loss: 0.2924 - val_accuracy: 0.9200 - val_loss: 0.2880\n",
            "Epoch 99/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9163 - loss: 0.2999 - val_accuracy: 0.9198 - val_loss: 0.2877\n",
            "Epoch 100/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9173 - loss: 0.2989 - val_accuracy: 0.9205 - val_loss: 0.2874\n",
            "Epoch 101/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9167 - loss: 0.2980 - val_accuracy: 0.9202 - val_loss: 0.2873\n",
            "Epoch 102/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9156 - loss: 0.2980 - val_accuracy: 0.9202 - val_loss: 0.2870\n",
            "Epoch 103/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9171 - loss: 0.2930 - val_accuracy: 0.9196 - val_loss: 0.2869\n",
            "Epoch 104/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9181 - loss: 0.2940 - val_accuracy: 0.9205 - val_loss: 0.2866\n",
            "Epoch 105/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9178 - loss: 0.2914 - val_accuracy: 0.9205 - val_loss: 0.2864\n",
            "Epoch 106/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9175 - loss: 0.2890 - val_accuracy: 0.9203 - val_loss: 0.2862\n",
            "Epoch 107/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9167 - loss: 0.2952 - val_accuracy: 0.9208 - val_loss: 0.2860\n",
            "Epoch 108/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9185 - loss: 0.2913 - val_accuracy: 0.9203 - val_loss: 0.2858\n",
            "Epoch 109/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9190 - loss: 0.2920 - val_accuracy: 0.9210 - val_loss: 0.2856\n",
            "Epoch 110/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9193 - loss: 0.2909 - val_accuracy: 0.9202 - val_loss: 0.2855\n",
            "Epoch 111/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9183 - loss: 0.2952 - val_accuracy: 0.9206 - val_loss: 0.2852\n",
            "Epoch 112/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9175 - loss: 0.2950 - val_accuracy: 0.9203 - val_loss: 0.2850\n",
            "Epoch 113/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9175 - loss: 0.2954 - val_accuracy: 0.9208 - val_loss: 0.2848\n",
            "Epoch 114/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9200 - loss: 0.2905 - val_accuracy: 0.9208 - val_loss: 0.2847\n",
            "Epoch 115/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9197 - loss: 0.2951 - val_accuracy: 0.9212 - val_loss: 0.2845\n",
            "Epoch 116/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9191 - loss: 0.2906 - val_accuracy: 0.9207 - val_loss: 0.2843\n",
            "Epoch 117/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9195 - loss: 0.2880 - val_accuracy: 0.9209 - val_loss: 0.2842\n",
            "Epoch 118/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9202 - loss: 0.2872 - val_accuracy: 0.9211 - val_loss: 0.2840\n",
            "Epoch 119/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9194 - loss: 0.2915 - val_accuracy: 0.9209 - val_loss: 0.2838\n",
            "Epoch 120/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9193 - loss: 0.2889 - val_accuracy: 0.9214 - val_loss: 0.2836\n",
            "Epoch 121/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9198 - loss: 0.2902 - val_accuracy: 0.9212 - val_loss: 0.2834\n",
            "Epoch 122/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9168 - loss: 0.2940 - val_accuracy: 0.9213 - val_loss: 0.2833\n",
            "Epoch 123/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9205 - loss: 0.2841 - val_accuracy: 0.9212 - val_loss: 0.2831\n",
            "Epoch 124/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9202 - loss: 0.2917 - val_accuracy: 0.9212 - val_loss: 0.2830\n",
            "Epoch 125/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9193 - loss: 0.2868 - val_accuracy: 0.9211 - val_loss: 0.2828\n",
            "Epoch 126/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9182 - loss: 0.2905 - val_accuracy: 0.9215 - val_loss: 0.2826\n",
            "Epoch 127/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9203 - loss: 0.2901 - val_accuracy: 0.9214 - val_loss: 0.2825\n",
            "Epoch 128/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9188 - loss: 0.2929 - val_accuracy: 0.9212 - val_loss: 0.2824\n",
            "Epoch 129/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9169 - loss: 0.2917 - val_accuracy: 0.9213 - val_loss: 0.2823\n",
            "Epoch 130/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9208 - loss: 0.2826 - val_accuracy: 0.9217 - val_loss: 0.2820\n",
            "Epoch 131/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9212 - loss: 0.2856 - val_accuracy: 0.9217 - val_loss: 0.2820\n",
            "Epoch 132/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9207 - loss: 0.2830 - val_accuracy: 0.9218 - val_loss: 0.2819\n",
            "Epoch 133/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9191 - loss: 0.2875 - val_accuracy: 0.9216 - val_loss: 0.2817\n",
            "Epoch 134/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9197 - loss: 0.2860 - val_accuracy: 0.9214 - val_loss: 0.2815\n",
            "Epoch 135/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9200 - loss: 0.2879 - val_accuracy: 0.9213 - val_loss: 0.2814\n",
            "Epoch 136/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9228 - loss: 0.2790 - val_accuracy: 0.9216 - val_loss: 0.2812\n",
            "Epoch 137/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9216 - loss: 0.2830 - val_accuracy: 0.9218 - val_loss: 0.2811\n",
            "Epoch 138/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9229 - loss: 0.2830 - val_accuracy: 0.9219 - val_loss: 0.2811\n",
            "Epoch 139/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9205 - loss: 0.2889 - val_accuracy: 0.9216 - val_loss: 0.2810\n",
            "Epoch 140/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9204 - loss: 0.2862 - val_accuracy: 0.9220 - val_loss: 0.2807\n",
            "Epoch 141/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9198 - loss: 0.2892 - val_accuracy: 0.9220 - val_loss: 0.2806\n",
            "Epoch 142/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9175 - loss: 0.2934 - val_accuracy: 0.9215 - val_loss: 0.2805\n",
            "Epoch 143/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9187 - loss: 0.2879 - val_accuracy: 0.9218 - val_loss: 0.2804\n",
            "Epoch 144/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9199 - loss: 0.2846 - val_accuracy: 0.9219 - val_loss: 0.2802\n",
            "Epoch 145/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9218 - loss: 0.2810 - val_accuracy: 0.9218 - val_loss: 0.2801\n",
            "Epoch 146/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9203 - loss: 0.2845 - val_accuracy: 0.9220 - val_loss: 0.2801\n",
            "Epoch 147/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9211 - loss: 0.2821 - val_accuracy: 0.9213 - val_loss: 0.2800\n",
            "Epoch 148/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9209 - loss: 0.2851 - val_accuracy: 0.9218 - val_loss: 0.2798\n",
            "Epoch 149/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9203 - loss: 0.2840 - val_accuracy: 0.9222 - val_loss: 0.2797\n",
            "Epoch 150/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9202 - loss: 0.2848 - val_accuracy: 0.9222 - val_loss: 0.2795\n",
            "Epoch 151/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9216 - loss: 0.2787 - val_accuracy: 0.9219 - val_loss: 0.2794\n",
            "Epoch 152/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9212 - loss: 0.2815 - val_accuracy: 0.9220 - val_loss: 0.2794\n",
            "Epoch 153/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9189 - loss: 0.2854 - val_accuracy: 0.9218 - val_loss: 0.2792\n",
            "Epoch 154/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9224 - loss: 0.2830 - val_accuracy: 0.9219 - val_loss: 0.2791\n",
            "Epoch 155/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9207 - loss: 0.2838 - val_accuracy: 0.9225 - val_loss: 0.2791\n",
            "Epoch 156/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9219 - loss: 0.2800 - val_accuracy: 0.9221 - val_loss: 0.2789\n",
            "Epoch 157/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9216 - loss: 0.2864 - val_accuracy: 0.9222 - val_loss: 0.2788\n",
            "Epoch 158/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9228 - loss: 0.2767 - val_accuracy: 0.9222 - val_loss: 0.2787\n",
            "Epoch 159/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9233 - loss: 0.2787 - val_accuracy: 0.9223 - val_loss: 0.2786\n",
            "Epoch 160/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9210 - loss: 0.2830 - val_accuracy: 0.9220 - val_loss: 0.2786\n",
            "Epoch 161/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9209 - loss: 0.2797 - val_accuracy: 0.9225 - val_loss: 0.2784\n",
            "Epoch 162/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9209 - loss: 0.2844 - val_accuracy: 0.9221 - val_loss: 0.2783\n",
            "Epoch 163/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9225 - loss: 0.2811 - val_accuracy: 0.9223 - val_loss: 0.2782\n",
            "Epoch 164/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9226 - loss: 0.2800 - val_accuracy: 0.9222 - val_loss: 0.2781\n",
            "Epoch 165/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9203 - loss: 0.2846 - val_accuracy: 0.9219 - val_loss: 0.2780\n",
            "Epoch 166/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9228 - loss: 0.2800 - val_accuracy: 0.9228 - val_loss: 0.2779\n",
            "Epoch 167/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9212 - loss: 0.2868 - val_accuracy: 0.9220 - val_loss: 0.2778\n",
            "Epoch 168/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9237 - loss: 0.2735 - val_accuracy: 0.9227 - val_loss: 0.2777\n",
            "Epoch 169/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9247 - loss: 0.2779 - val_accuracy: 0.9224 - val_loss: 0.2776\n",
            "Epoch 170/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9220 - loss: 0.2782 - val_accuracy: 0.9222 - val_loss: 0.2775\n",
            "Epoch 171/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9225 - loss: 0.2782 - val_accuracy: 0.9222 - val_loss: 0.2774\n",
            "Epoch 172/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9217 - loss: 0.2807 - val_accuracy: 0.9225 - val_loss: 0.2773\n",
            "Epoch 173/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9224 - loss: 0.2793 - val_accuracy: 0.9223 - val_loss: 0.2773\n",
            "Epoch 174/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9227 - loss: 0.2792 - val_accuracy: 0.9224 - val_loss: 0.2772\n",
            "Epoch 175/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9224 - loss: 0.2791 - val_accuracy: 0.9224 - val_loss: 0.2771\n",
            "Epoch 176/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9221 - loss: 0.2757 - val_accuracy: 0.9225 - val_loss: 0.2770\n",
            "Epoch 177/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9235 - loss: 0.2717 - val_accuracy: 0.9227 - val_loss: 0.2769\n",
            "Epoch 178/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9217 - loss: 0.2852 - val_accuracy: 0.9225 - val_loss: 0.2768\n",
            "Epoch 179/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9244 - loss: 0.2741 - val_accuracy: 0.9224 - val_loss: 0.2768\n",
            "Epoch 180/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9230 - loss: 0.2794 - val_accuracy: 0.9225 - val_loss: 0.2767\n",
            "Epoch 181/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9215 - loss: 0.2826 - val_accuracy: 0.9228 - val_loss: 0.2766\n",
            "Epoch 182/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9217 - loss: 0.2809 - val_accuracy: 0.9227 - val_loss: 0.2765\n",
            "Epoch 183/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9235 - loss: 0.2736 - val_accuracy: 0.9225 - val_loss: 0.2764\n",
            "Epoch 184/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9220 - loss: 0.2795 - val_accuracy: 0.9232 - val_loss: 0.2764\n",
            "Epoch 185/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9206 - loss: 0.2826 - val_accuracy: 0.9229 - val_loss: 0.2762\n",
            "Epoch 186/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9208 - loss: 0.2791 - val_accuracy: 0.9226 - val_loss: 0.2762\n",
            "Epoch 187/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9222 - loss: 0.2807 - val_accuracy: 0.9232 - val_loss: 0.2762\n",
            "Epoch 188/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9227 - loss: 0.2759 - val_accuracy: 0.9235 - val_loss: 0.2761\n",
            "Epoch 189/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9211 - loss: 0.2840 - val_accuracy: 0.9236 - val_loss: 0.2760\n",
            "Epoch 190/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9224 - loss: 0.2773 - val_accuracy: 0.9234 - val_loss: 0.2760\n",
            "Epoch 191/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9218 - loss: 0.2832 - val_accuracy: 0.9238 - val_loss: 0.2758\n",
            "Epoch 192/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9208 - loss: 0.2821 - val_accuracy: 0.9227 - val_loss: 0.2758\n",
            "Epoch 193/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9222 - loss: 0.2808 - val_accuracy: 0.9237 - val_loss: 0.2756\n",
            "Epoch 194/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9223 - loss: 0.2748 - val_accuracy: 0.9238 - val_loss: 0.2756\n",
            "Epoch 195/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9213 - loss: 0.2802 - val_accuracy: 0.9237 - val_loss: 0.2756\n",
            "Epoch 196/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9224 - loss: 0.2837 - val_accuracy: 0.9241 - val_loss: 0.2755\n",
            "Epoch 197/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9235 - loss: 0.2747 - val_accuracy: 0.9239 - val_loss: 0.2754\n",
            "Epoch 198/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9226 - loss: 0.2797 - val_accuracy: 0.9237 - val_loss: 0.2753\n",
            "Epoch 199/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9232 - loss: 0.2751 - val_accuracy: 0.9231 - val_loss: 0.2754\n",
            "Epoch 200/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9224 - loss: 0.2797 - val_accuracy: 0.9241 - val_loss: 0.2752\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f6cb1c87310>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Training the model.\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=BATCH_SIZE, epochs=EPOCHS,\n",
        "          verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuONY5G5r78g",
        "outputId": "0905861f-8a52-4092-fc3e-95065cec0046"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9108 - loss: 0.3161\n",
            "Test accuracy: 0.9226999878883362\n"
          ]
        }
      ],
      "source": [
        "#evaluate the model\n",
        "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7U7Y-U9MXvqz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Improving the simple net in TensorFlow with hidden layers\n",
        "\n"
      ],
      "metadata": {
        "id": "IwjX-2tsjKEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "# Network and training.\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 128\n",
        "VERBOSE = 1\n",
        "NB_CLASSES = 10   # number of outputs = number of digits\n",
        "N_HIDDEN = 128\n",
        "VALIDATION_SPLIT = 0.2 # how much TRAIN is reserved for VALIDATION\n",
        "# Loading MNIST dataset.\n",
        "# Labels have one-hot representation.\n",
        "mnist = keras.datasets.mnist\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
        "# X_train is 60000 rows of 28x28 values; we reshape it to 60000 x 784.\n",
        "RESHAPED = 784\n",
        "#\n",
        "X_train = X_train.reshape(60000, RESHAPED)\n",
        "X_test = X_test.reshape(10000, RESHAPED)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "# Normalize inputs to be within in [0, 1].\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "# Labels have one-hot representation.\n",
        "Y_train = tf.keras.utils.to_categorical(Y_train, NB_CLASSES)\n",
        "Y_test = tf.keras.utils.to_categorical(Y_test, NB_CLASSES)\n",
        "# Build the model.\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(keras.layers.Dense(N_HIDDEN,\n",
        "             input_shape=(RESHAPED,),\n",
        "             name='dense_layer', activation='relu'))\n",
        "model.add(keras.layers.Dense(N_HIDDEN,\n",
        "             name='dense_layer_2', activation='relu'))\n",
        "model.add(keras.layers.Dense(NB_CLASSES,\n",
        "             name='dense_layer_3', activation='softmax'))\n",
        "# Summary of the model.\n",
        "model.summary()\n",
        "# Compiling the model.\n",
        "model.compile(optimizer='SGD',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "# Training the model.\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=BATCH_SIZE, epochs=EPOCHS,\n",
        "          verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
        "# Evaluating the model.\n",
        "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "05uTaff7jMEn",
        "outputId": "4432d37d-3cac-4436-a6c6-7bf7f45616d2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_layer (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m100,480\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_layer_2 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_layer_3 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,290\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m118,282\u001b[0m (462.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">118,282</span> (462.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m118,282\u001b[0m (462.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">118,282</span> (462.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4401 - loss: 1.8610 - val_accuracy: 0.8369 - val_loss: 0.7479\n",
            "Epoch 2/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8395 - loss: 0.6696 - val_accuracy: 0.8838 - val_loss: 0.4603\n",
            "Epoch 3/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8790 - loss: 0.4612 - val_accuracy: 0.8988 - val_loss: 0.3771\n",
            "Epoch 4/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8899 - loss: 0.3897 - val_accuracy: 0.9061 - val_loss: 0.3388\n",
            "Epoch 5/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9024 - loss: 0.3508 - val_accuracy: 0.9124 - val_loss: 0.3141\n",
            "Epoch 6/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9073 - loss: 0.3273 - val_accuracy: 0.9178 - val_loss: 0.2960\n",
            "Epoch 7/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9125 - loss: 0.3066 - val_accuracy: 0.9218 - val_loss: 0.2823\n",
            "Epoch 8/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9168 - loss: 0.2932 - val_accuracy: 0.9260 - val_loss: 0.2702\n",
            "Epoch 9/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9201 - loss: 0.2788 - val_accuracy: 0.9285 - val_loss: 0.2598\n",
            "Epoch 10/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9245 - loss: 0.2608 - val_accuracy: 0.9309 - val_loss: 0.2503\n",
            "Epoch 11/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9272 - loss: 0.2573 - val_accuracy: 0.9332 - val_loss: 0.2420\n",
            "Epoch 12/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9296 - loss: 0.2485 - val_accuracy: 0.9343 - val_loss: 0.2354\n",
            "Epoch 13/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9328 - loss: 0.2397 - val_accuracy: 0.9365 - val_loss: 0.2283\n",
            "Epoch 14/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9336 - loss: 0.2336 - val_accuracy: 0.9394 - val_loss: 0.2213\n",
            "Epoch 15/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9362 - loss: 0.2188 - val_accuracy: 0.9403 - val_loss: 0.2161\n",
            "Epoch 16/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9370 - loss: 0.2223 - val_accuracy: 0.9419 - val_loss: 0.2100\n",
            "Epoch 17/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9413 - loss: 0.2104 - val_accuracy: 0.9410 - val_loss: 0.2061\n",
            "Epoch 18/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9408 - loss: 0.2066 - val_accuracy: 0.9438 - val_loss: 0.2008\n",
            "Epoch 19/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9424 - loss: 0.1999 - val_accuracy: 0.9461 - val_loss: 0.1954\n",
            "Epoch 20/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9463 - loss: 0.1901 - val_accuracy: 0.9467 - val_loss: 0.1914\n",
            "Epoch 21/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.1914 - val_accuracy: 0.9477 - val_loss: 0.1874\n",
            "Epoch 22/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9466 - loss: 0.1848 - val_accuracy: 0.9487 - val_loss: 0.1832\n",
            "Epoch 23/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9478 - loss: 0.1777 - val_accuracy: 0.9488 - val_loss: 0.1800\n",
            "Epoch 24/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9511 - loss: 0.1698 - val_accuracy: 0.9507 - val_loss: 0.1772\n",
            "Epoch 25/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9495 - loss: 0.1716 - val_accuracy: 0.9508 - val_loss: 0.1736\n",
            "Epoch 26/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9512 - loss: 0.1698 - val_accuracy: 0.9536 - val_loss: 0.1703\n",
            "Epoch 27/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9548 - loss: 0.1621 - val_accuracy: 0.9537 - val_loss: 0.1679\n",
            "Epoch 28/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9559 - loss: 0.1531 - val_accuracy: 0.9538 - val_loss: 0.1657\n",
            "Epoch 29/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9579 - loss: 0.1477 - val_accuracy: 0.9558 - val_loss: 0.1620\n",
            "Epoch 30/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9559 - loss: 0.1527 - val_accuracy: 0.9567 - val_loss: 0.1593\n",
            "Epoch 31/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9592 - loss: 0.1448 - val_accuracy: 0.9564 - val_loss: 0.1576\n",
            "Epoch 32/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9591 - loss: 0.1422 - val_accuracy: 0.9571 - val_loss: 0.1552\n",
            "Epoch 33/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9600 - loss: 0.1393 - val_accuracy: 0.9596 - val_loss: 0.1527\n",
            "Epoch 34/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9615 - loss: 0.1359 - val_accuracy: 0.9598 - val_loss: 0.1506\n",
            "Epoch 35/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9617 - loss: 0.1360 - val_accuracy: 0.9589 - val_loss: 0.1497\n",
            "Epoch 36/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9633 - loss: 0.1327 - val_accuracy: 0.9602 - val_loss: 0.1478\n",
            "Epoch 37/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9634 - loss: 0.1335 - val_accuracy: 0.9610 - val_loss: 0.1449\n",
            "Epoch 38/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9649 - loss: 0.1248 - val_accuracy: 0.9613 - val_loss: 0.1436\n",
            "Epoch 39/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9650 - loss: 0.1225 - val_accuracy: 0.9622 - val_loss: 0.1419\n",
            "Epoch 40/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9657 - loss: 0.1192 - val_accuracy: 0.9626 - val_loss: 0.1400\n",
            "Epoch 41/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9652 - loss: 0.1214 - val_accuracy: 0.9622 - val_loss: 0.1388\n",
            "Epoch 42/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9661 - loss: 0.1174 - val_accuracy: 0.9626 - val_loss: 0.1367\n",
            "Epoch 43/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9672 - loss: 0.1158 - val_accuracy: 0.9634 - val_loss: 0.1350\n",
            "Epoch 44/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9686 - loss: 0.1123 - val_accuracy: 0.9638 - val_loss: 0.1348\n",
            "Epoch 45/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9685 - loss: 0.1090 - val_accuracy: 0.9626 - val_loss: 0.1331\n",
            "Epoch 46/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9708 - loss: 0.1052 - val_accuracy: 0.9639 - val_loss: 0.1321\n",
            "Epoch 47/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9707 - loss: 0.1060 - val_accuracy: 0.9642 - val_loss: 0.1300\n",
            "Epoch 48/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9710 - loss: 0.1031 - val_accuracy: 0.9647 - val_loss: 0.1288\n",
            "Epoch 49/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9728 - loss: 0.0993 - val_accuracy: 0.9652 - val_loss: 0.1276\n",
            "Epoch 50/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9728 - loss: 0.0989 - val_accuracy: 0.9648 - val_loss: 0.1274\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9566 - loss: 0.1454\n",
            "Test accuracy: 0.9628999829292297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mMHmeDcfjSs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Further improving the simple net in TensorFlow with dropout"
      ],
      "metadata": {
        "id": "xH3hsFjoj9W-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "# Network and training.\n",
        "EPOCHS = 200\n",
        "BATCH_SIZE = 128\n",
        "VERBOSE = 1\n",
        "NB_CLASSES = 10   # number of outputs = number of digits\n",
        "N_HIDDEN = 128\n",
        "VALIDATION_SPLIT = 0.2 # how much TRAIN is reserved for VALIDATION\n",
        "DROPOUT = 0.3\n",
        "# Loading MNIST dataset.\n",
        "# Labels have one-hot representation.\n",
        "mnist = keras.datasets.mnist\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
        "# X_train is 60000 rows of 28x28 values; we reshape it to 60000 x 784.\n",
        "RESHAPED = 784\n",
        "#\n",
        "X_train = X_train.reshape(60000, RESHAPED)\n",
        "X_test = X_test.reshape(10000, RESHAPED)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "# Normalize inputs within [0, 1].\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "# One-hot representations for labels.\n",
        "Y_train = tf.keras.utils.to_categorical(Y_train, NB_CLASSES)\n",
        "Y_test = tf.keras.utils.to_categorical(Y_test, NB_CLASSES)\n",
        "# Building the model.\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(keras.layers.Dense(N_HIDDEN,\n",
        "              input_shape=(RESHAPED,),\n",
        "              name='dense_layer', activation='relu'))\n",
        "model.add(keras.layers.Dropout(DROPOUT))\n",
        "model.add(keras.layers.Dense(N_HIDDEN,\n",
        "              name='dense_layer_2', activation='relu'))\n",
        "model.add(keras.layers.Dropout(DROPOUT))\n",
        "model.add(keras.layers.Dense(NB_CLASSES,\n",
        "              name='dense_layer_3', activation='softmax'))\n",
        "# Summary of the model.\n",
        "model.summary()\n",
        "# Compiling the model.\n",
        "model.compile(optimizer='SGD',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "# Training the model.\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=BATCH_SIZE, epochs=EPOCHS,\n",
        "          verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
        "# Evaluating the model.\n",
        "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KjQtHXQUj_Qw",
        "outputId": "afaaa4b3-d149-4f86-800d-20e5ad2a8b30"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_layer (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m100,480\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_layer_2 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_layer_3 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,290\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m118,282\u001b[0m (462.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">118,282</span> (462.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m118,282\u001b[0m (462.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">118,282</span> (462.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3081 - loss: 2.0267 - val_accuracy: 0.8033 - val_loss: 0.9121\n",
            "Epoch 2/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6819 - loss: 1.0250 - val_accuracy: 0.8654 - val_loss: 0.5352\n",
            "Epoch 3/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7745 - loss: 0.7334 - val_accuracy: 0.8895 - val_loss: 0.4244\n",
            "Epoch 4/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8124 - loss: 0.6102 - val_accuracy: 0.8984 - val_loss: 0.3716\n",
            "Epoch 5/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8385 - loss: 0.5380 - val_accuracy: 0.9055 - val_loss: 0.3364\n",
            "Epoch 6/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8515 - loss: 0.4997 - val_accuracy: 0.9105 - val_loss: 0.3133\n",
            "Epoch 7/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8600 - loss: 0.4712 - val_accuracy: 0.9147 - val_loss: 0.2944\n",
            "Epoch 8/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8724 - loss: 0.4353 - val_accuracy: 0.9187 - val_loss: 0.2784\n",
            "Epoch 9/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8792 - loss: 0.4055 - val_accuracy: 0.9222 - val_loss: 0.2674\n",
            "Epoch 10/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8852 - loss: 0.3931 - val_accuracy: 0.9256 - val_loss: 0.2561\n",
            "Epoch 11/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8895 - loss: 0.3809 - val_accuracy: 0.9287 - val_loss: 0.2444\n",
            "Epoch 12/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8931 - loss: 0.3613 - val_accuracy: 0.9313 - val_loss: 0.2374\n",
            "Epoch 13/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8961 - loss: 0.3502 - val_accuracy: 0.9337 - val_loss: 0.2286\n",
            "Epoch 14/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8998 - loss: 0.3369 - val_accuracy: 0.9358 - val_loss: 0.2212\n",
            "Epoch 15/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9039 - loss: 0.3249 - val_accuracy: 0.9372 - val_loss: 0.2151\n",
            "Epoch 16/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9064 - loss: 0.3198 - val_accuracy: 0.9394 - val_loss: 0.2087\n",
            "Epoch 17/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9090 - loss: 0.3063 - val_accuracy: 0.9417 - val_loss: 0.2032\n",
            "Epoch 18/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9117 - loss: 0.2995 - val_accuracy: 0.9427 - val_loss: 0.1984\n",
            "Epoch 19/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9137 - loss: 0.2979 - val_accuracy: 0.9455 - val_loss: 0.1930\n",
            "Epoch 20/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9165 - loss: 0.2854 - val_accuracy: 0.9463 - val_loss: 0.1895\n",
            "Epoch 21/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9175 - loss: 0.2799 - val_accuracy: 0.9473 - val_loss: 0.1860\n",
            "Epoch 22/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9183 - loss: 0.2701 - val_accuracy: 0.9491 - val_loss: 0.1816\n",
            "Epoch 23/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9235 - loss: 0.2614 - val_accuracy: 0.9495 - val_loss: 0.1781\n",
            "Epoch 24/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9248 - loss: 0.2576 - val_accuracy: 0.9508 - val_loss: 0.1745\n",
            "Epoch 25/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9234 - loss: 0.2607 - val_accuracy: 0.9513 - val_loss: 0.1712\n",
            "Epoch 26/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9251 - loss: 0.2532 - val_accuracy: 0.9523 - val_loss: 0.1681\n",
            "Epoch 27/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9270 - loss: 0.2470 - val_accuracy: 0.9530 - val_loss: 0.1652\n",
            "Epoch 28/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9269 - loss: 0.2474 - val_accuracy: 0.9537 - val_loss: 0.1629\n",
            "Epoch 29/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.9293 - loss: 0.2402 - val_accuracy: 0.9538 - val_loss: 0.1606\n",
            "Epoch 30/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9310 - loss: 0.2335 - val_accuracy: 0.9550 - val_loss: 0.1575\n",
            "Epoch 31/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9285 - loss: 0.2374 - val_accuracy: 0.9553 - val_loss: 0.1551\n",
            "Epoch 32/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9328 - loss: 0.2288 - val_accuracy: 0.9560 - val_loss: 0.1529\n",
            "Epoch 33/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9342 - loss: 0.2257 - val_accuracy: 0.9559 - val_loss: 0.1507\n",
            "Epoch 34/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9361 - loss: 0.2185 - val_accuracy: 0.9578 - val_loss: 0.1487\n",
            "Epoch 35/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9370 - loss: 0.2172 - val_accuracy: 0.9576 - val_loss: 0.1467\n",
            "Epoch 36/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9363 - loss: 0.2169 - val_accuracy: 0.9588 - val_loss: 0.1449\n",
            "Epoch 37/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9355 - loss: 0.2109 - val_accuracy: 0.9591 - val_loss: 0.1430\n",
            "Epoch 38/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9404 - loss: 0.2086 - val_accuracy: 0.9597 - val_loss: 0.1413\n",
            "Epoch 39/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9414 - loss: 0.2038 - val_accuracy: 0.9597 - val_loss: 0.1392\n",
            "Epoch 40/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9391 - loss: 0.2018 - val_accuracy: 0.9613 - val_loss: 0.1381\n",
            "Epoch 41/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9401 - loss: 0.2025 - val_accuracy: 0.9622 - val_loss: 0.1365\n",
            "Epoch 42/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9405 - loss: 0.1962 - val_accuracy: 0.9621 - val_loss: 0.1350\n",
            "Epoch 43/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9428 - loss: 0.1945 - val_accuracy: 0.9623 - val_loss: 0.1340\n",
            "Epoch 44/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9441 - loss: 0.1907 - val_accuracy: 0.9628 - val_loss: 0.1322\n",
            "Epoch 45/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9421 - loss: 0.1947 - val_accuracy: 0.9627 - val_loss: 0.1311\n",
            "Epoch 46/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9453 - loss: 0.1858 - val_accuracy: 0.9632 - val_loss: 0.1300\n",
            "Epoch 47/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9470 - loss: 0.1830 - val_accuracy: 0.9628 - val_loss: 0.1292\n",
            "Epoch 48/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9478 - loss: 0.1798 - val_accuracy: 0.9637 - val_loss: 0.1270\n",
            "Epoch 49/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9467 - loss: 0.1818 - val_accuracy: 0.9644 - val_loss: 0.1263\n",
            "Epoch 50/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9470 - loss: 0.1815 - val_accuracy: 0.9641 - val_loss: 0.1245\n",
            "Epoch 51/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9476 - loss: 0.1772 - val_accuracy: 0.9653 - val_loss: 0.1236\n",
            "Epoch 52/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9485 - loss: 0.1747 - val_accuracy: 0.9657 - val_loss: 0.1222\n",
            "Epoch 53/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9469 - loss: 0.1752 - val_accuracy: 0.9659 - val_loss: 0.1210\n",
            "Epoch 54/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9485 - loss: 0.1754 - val_accuracy: 0.9661 - val_loss: 0.1202\n",
            "Epoch 55/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9502 - loss: 0.1669 - val_accuracy: 0.9657 - val_loss: 0.1202\n",
            "Epoch 56/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9525 - loss: 0.1605 - val_accuracy: 0.9659 - val_loss: 0.1183\n",
            "Epoch 57/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9495 - loss: 0.1710 - val_accuracy: 0.9662 - val_loss: 0.1175\n",
            "Epoch 58/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9529 - loss: 0.1570 - val_accuracy: 0.9658 - val_loss: 0.1167\n",
            "Epoch 59/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9511 - loss: 0.1641 - val_accuracy: 0.9664 - val_loss: 0.1160\n",
            "Epoch 60/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9513 - loss: 0.1641 - val_accuracy: 0.9666 - val_loss: 0.1149\n",
            "Epoch 61/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9525 - loss: 0.1613 - val_accuracy: 0.9668 - val_loss: 0.1143\n",
            "Epoch 62/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9530 - loss: 0.1590 - val_accuracy: 0.9671 - val_loss: 0.1133\n",
            "Epoch 63/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9519 - loss: 0.1606 - val_accuracy: 0.9674 - val_loss: 0.1129\n",
            "Epoch 64/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9536 - loss: 0.1534 - val_accuracy: 0.9669 - val_loss: 0.1121\n",
            "Epoch 65/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9529 - loss: 0.1533 - val_accuracy: 0.9675 - val_loss: 0.1108\n",
            "Epoch 66/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9534 - loss: 0.1542 - val_accuracy: 0.9674 - val_loss: 0.1102\n",
            "Epoch 67/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9550 - loss: 0.1517 - val_accuracy: 0.9678 - val_loss: 0.1101\n",
            "Epoch 68/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9552 - loss: 0.1509 - val_accuracy: 0.9682 - val_loss: 0.1086\n",
            "Epoch 69/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9560 - loss: 0.1496 - val_accuracy: 0.9686 - val_loss: 0.1076\n",
            "Epoch 70/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9546 - loss: 0.1530 - val_accuracy: 0.9689 - val_loss: 0.1074\n",
            "Epoch 71/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9563 - loss: 0.1437 - val_accuracy: 0.9687 - val_loss: 0.1072\n",
            "Epoch 72/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9553 - loss: 0.1505 - val_accuracy: 0.9687 - val_loss: 0.1066\n",
            "Epoch 73/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9559 - loss: 0.1499 - val_accuracy: 0.9693 - val_loss: 0.1057\n",
            "Epoch 74/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9578 - loss: 0.1463 - val_accuracy: 0.9699 - val_loss: 0.1053\n",
            "Epoch 75/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9585 - loss: 0.1404 - val_accuracy: 0.9698 - val_loss: 0.1043\n",
            "Epoch 76/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9578 - loss: 0.1374 - val_accuracy: 0.9703 - val_loss: 0.1038\n",
            "Epoch 77/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9581 - loss: 0.1398 - val_accuracy: 0.9693 - val_loss: 0.1038\n",
            "Epoch 78/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9594 - loss: 0.1350 - val_accuracy: 0.9703 - val_loss: 0.1025\n",
            "Epoch 79/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9595 - loss: 0.1355 - val_accuracy: 0.9712 - val_loss: 0.1021\n",
            "Epoch 80/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9580 - loss: 0.1447 - val_accuracy: 0.9712 - val_loss: 0.1015\n",
            "Epoch 81/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9583 - loss: 0.1372 - val_accuracy: 0.9712 - val_loss: 0.1009\n",
            "Epoch 82/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9616 - loss: 0.1291 - val_accuracy: 0.9715 - val_loss: 0.1010\n",
            "Epoch 83/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9616 - loss: 0.1305 - val_accuracy: 0.9710 - val_loss: 0.1000\n",
            "Epoch 84/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9614 - loss: 0.1323 - val_accuracy: 0.9714 - val_loss: 0.0998\n",
            "Epoch 85/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9592 - loss: 0.1332 - val_accuracy: 0.9716 - val_loss: 0.0991\n",
            "Epoch 86/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9608 - loss: 0.1309 - val_accuracy: 0.9721 - val_loss: 0.0992\n",
            "Epoch 87/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9612 - loss: 0.1303 - val_accuracy: 0.9713 - val_loss: 0.0990\n",
            "Epoch 88/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9630 - loss: 0.1292 - val_accuracy: 0.9722 - val_loss: 0.0987\n",
            "Epoch 89/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9622 - loss: 0.1261 - val_accuracy: 0.9720 - val_loss: 0.0981\n",
            "Epoch 90/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9620 - loss: 0.1284 - val_accuracy: 0.9717 - val_loss: 0.0975\n",
            "Epoch 91/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9631 - loss: 0.1248 - val_accuracy: 0.9722 - val_loss: 0.0972\n",
            "Epoch 92/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9610 - loss: 0.1295 - val_accuracy: 0.9724 - val_loss: 0.0963\n",
            "Epoch 93/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9626 - loss: 0.1236 - val_accuracy: 0.9727 - val_loss: 0.0967\n",
            "Epoch 94/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9638 - loss: 0.1224 - val_accuracy: 0.9728 - val_loss: 0.0955\n",
            "Epoch 95/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9640 - loss: 0.1224 - val_accuracy: 0.9722 - val_loss: 0.0956\n",
            "Epoch 96/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9647 - loss: 0.1191 - val_accuracy: 0.9725 - val_loss: 0.0952\n",
            "Epoch 97/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9630 - loss: 0.1216 - val_accuracy: 0.9718 - val_loss: 0.0953\n",
            "Epoch 98/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9615 - loss: 0.1223 - val_accuracy: 0.9725 - val_loss: 0.0941\n",
            "Epoch 99/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9652 - loss: 0.1147 - val_accuracy: 0.9726 - val_loss: 0.0942\n",
            "Epoch 100/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9623 - loss: 0.1235 - val_accuracy: 0.9722 - val_loss: 0.0941\n",
            "Epoch 101/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9631 - loss: 0.1184 - val_accuracy: 0.9727 - val_loss: 0.0936\n",
            "Epoch 102/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9640 - loss: 0.1168 - val_accuracy: 0.9727 - val_loss: 0.0927\n",
            "Epoch 103/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9641 - loss: 0.1172 - val_accuracy: 0.9729 - val_loss: 0.0931\n",
            "Epoch 104/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9642 - loss: 0.1188 - val_accuracy: 0.9729 - val_loss: 0.0930\n",
            "Epoch 105/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9665 - loss: 0.1106 - val_accuracy: 0.9731 - val_loss: 0.0918\n",
            "Epoch 106/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9656 - loss: 0.1108 - val_accuracy: 0.9730 - val_loss: 0.0920\n",
            "Epoch 107/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9668 - loss: 0.1089 - val_accuracy: 0.9729 - val_loss: 0.0924\n",
            "Epoch 108/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9661 - loss: 0.1114 - val_accuracy: 0.9736 - val_loss: 0.0915\n",
            "Epoch 109/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9652 - loss: 0.1147 - val_accuracy: 0.9733 - val_loss: 0.0911\n",
            "Epoch 110/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9662 - loss: 0.1137 - val_accuracy: 0.9735 - val_loss: 0.0908\n",
            "Epoch 111/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9676 - loss: 0.1050 - val_accuracy: 0.9735 - val_loss: 0.0912\n",
            "Epoch 112/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9690 - loss: 0.1069 - val_accuracy: 0.9737 - val_loss: 0.0901\n",
            "Epoch 113/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9678 - loss: 0.1075 - val_accuracy: 0.9739 - val_loss: 0.0905\n",
            "Epoch 114/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9685 - loss: 0.1074 - val_accuracy: 0.9741 - val_loss: 0.0899\n",
            "Epoch 115/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9664 - loss: 0.1113 - val_accuracy: 0.9737 - val_loss: 0.0897\n",
            "Epoch 116/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9685 - loss: 0.1044 - val_accuracy: 0.9740 - val_loss: 0.0896\n",
            "Epoch 117/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9680 - loss: 0.1067 - val_accuracy: 0.9740 - val_loss: 0.0891\n",
            "Epoch 118/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9681 - loss: 0.1056 - val_accuracy: 0.9737 - val_loss: 0.0888\n",
            "Epoch 119/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.9690 - loss: 0.1038 - val_accuracy: 0.9734 - val_loss: 0.0892\n",
            "Epoch 120/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9694 - loss: 0.1020 - val_accuracy: 0.9744 - val_loss: 0.0885\n",
            "Epoch 121/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9686 - loss: 0.1034 - val_accuracy: 0.9735 - val_loss: 0.0888\n",
            "Epoch 122/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9685 - loss: 0.1028 - val_accuracy: 0.9737 - val_loss: 0.0885\n",
            "Epoch 123/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9695 - loss: 0.1010 - val_accuracy: 0.9743 - val_loss: 0.0879\n",
            "Epoch 124/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9695 - loss: 0.0980 - val_accuracy: 0.9743 - val_loss: 0.0878\n",
            "Epoch 125/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9673 - loss: 0.1077 - val_accuracy: 0.9743 - val_loss: 0.0875\n",
            "Epoch 126/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9697 - loss: 0.1018 - val_accuracy: 0.9746 - val_loss: 0.0873\n",
            "Epoch 127/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9687 - loss: 0.1005 - val_accuracy: 0.9745 - val_loss: 0.0874\n",
            "Epoch 128/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9703 - loss: 0.1001 - val_accuracy: 0.9744 - val_loss: 0.0868\n",
            "Epoch 129/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9703 - loss: 0.0997 - val_accuracy: 0.9748 - val_loss: 0.0865\n",
            "Epoch 130/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9688 - loss: 0.1024 - val_accuracy: 0.9746 - val_loss: 0.0865\n",
            "Epoch 131/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9698 - loss: 0.0994 - val_accuracy: 0.9749 - val_loss: 0.0863\n",
            "Epoch 132/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9696 - loss: 0.0989 - val_accuracy: 0.9748 - val_loss: 0.0860\n",
            "Epoch 133/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9695 - loss: 0.0980 - val_accuracy: 0.9753 - val_loss: 0.0853\n",
            "Epoch 134/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9713 - loss: 0.0974 - val_accuracy: 0.9746 - val_loss: 0.0859\n",
            "Epoch 135/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9709 - loss: 0.0955 - val_accuracy: 0.9753 - val_loss: 0.0855\n",
            "Epoch 136/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9717 - loss: 0.0961 - val_accuracy: 0.9750 - val_loss: 0.0850\n",
            "Epoch 137/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9703 - loss: 0.0957 - val_accuracy: 0.9747 - val_loss: 0.0848\n",
            "Epoch 138/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9713 - loss: 0.0939 - val_accuracy: 0.9749 - val_loss: 0.0847\n",
            "Epoch 139/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9707 - loss: 0.0948 - val_accuracy: 0.9748 - val_loss: 0.0850\n",
            "Epoch 140/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9710 - loss: 0.0965 - val_accuracy: 0.9751 - val_loss: 0.0852\n",
            "Epoch 141/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9711 - loss: 0.0956 - val_accuracy: 0.9758 - val_loss: 0.0848\n",
            "Epoch 142/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9702 - loss: 0.0938 - val_accuracy: 0.9751 - val_loss: 0.0848\n",
            "Epoch 143/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9732 - loss: 0.0881 - val_accuracy: 0.9751 - val_loss: 0.0844\n",
            "Epoch 144/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9718 - loss: 0.0940 - val_accuracy: 0.9753 - val_loss: 0.0842\n",
            "Epoch 145/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9726 - loss: 0.0943 - val_accuracy: 0.9756 - val_loss: 0.0842\n",
            "Epoch 146/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9733 - loss: 0.0905 - val_accuracy: 0.9759 - val_loss: 0.0836\n",
            "Epoch 147/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9722 - loss: 0.0937 - val_accuracy: 0.9753 - val_loss: 0.0837\n",
            "Epoch 148/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9733 - loss: 0.0890 - val_accuracy: 0.9761 - val_loss: 0.0835\n",
            "Epoch 149/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9735 - loss: 0.0893 - val_accuracy: 0.9755 - val_loss: 0.0838\n",
            "Epoch 150/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9734 - loss: 0.0861 - val_accuracy: 0.9754 - val_loss: 0.0835\n",
            "Epoch 151/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9737 - loss: 0.0835 - val_accuracy: 0.9755 - val_loss: 0.0836\n",
            "Epoch 152/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9717 - loss: 0.0927 - val_accuracy: 0.9754 - val_loss: 0.0838\n",
            "Epoch 153/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9725 - loss: 0.0864 - val_accuracy: 0.9760 - val_loss: 0.0828\n",
            "Epoch 154/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9728 - loss: 0.0889 - val_accuracy: 0.9757 - val_loss: 0.0826\n",
            "Epoch 155/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9745 - loss: 0.0852 - val_accuracy: 0.9757 - val_loss: 0.0827\n",
            "Epoch 156/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9715 - loss: 0.0903 - val_accuracy: 0.9758 - val_loss: 0.0829\n",
            "Epoch 157/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9732 - loss: 0.0865 - val_accuracy: 0.9760 - val_loss: 0.0824\n",
            "Epoch 158/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9726 - loss: 0.0873 - val_accuracy: 0.9757 - val_loss: 0.0824\n",
            "Epoch 159/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.9712 - loss: 0.0921 - val_accuracy: 0.9762 - val_loss: 0.0816\n",
            "Epoch 160/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9726 - loss: 0.0874 - val_accuracy: 0.9763 - val_loss: 0.0822\n",
            "Epoch 161/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9741 - loss: 0.0864 - val_accuracy: 0.9762 - val_loss: 0.0819\n",
            "Epoch 162/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9732 - loss: 0.0873 - val_accuracy: 0.9762 - val_loss: 0.0822\n",
            "Epoch 163/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9725 - loss: 0.0876 - val_accuracy: 0.9761 - val_loss: 0.0821\n",
            "Epoch 164/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9742 - loss: 0.0840 - val_accuracy: 0.9762 - val_loss: 0.0820\n",
            "Epoch 165/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9733 - loss: 0.0871 - val_accuracy: 0.9759 - val_loss: 0.0812\n",
            "Epoch 166/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9744 - loss: 0.0838 - val_accuracy: 0.9762 - val_loss: 0.0817\n",
            "Epoch 167/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9748 - loss: 0.0804 - val_accuracy: 0.9762 - val_loss: 0.0818\n",
            "Epoch 168/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9737 - loss: 0.0842 - val_accuracy: 0.9768 - val_loss: 0.0812\n",
            "Epoch 169/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9733 - loss: 0.0838 - val_accuracy: 0.9761 - val_loss: 0.0810\n",
            "Epoch 170/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9748 - loss: 0.0802 - val_accuracy: 0.9764 - val_loss: 0.0819\n",
            "Epoch 171/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9754 - loss: 0.0807 - val_accuracy: 0.9762 - val_loss: 0.0808\n",
            "Epoch 172/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9748 - loss: 0.0815 - val_accuracy: 0.9764 - val_loss: 0.0806\n",
            "Epoch 173/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9756 - loss: 0.0842 - val_accuracy: 0.9765 - val_loss: 0.0810\n",
            "Epoch 174/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9743 - loss: 0.0823 - val_accuracy: 0.9761 - val_loss: 0.0809\n",
            "Epoch 175/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9762 - loss: 0.0789 - val_accuracy: 0.9767 - val_loss: 0.0808\n",
            "Epoch 176/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9748 - loss: 0.0820 - val_accuracy: 0.9766 - val_loss: 0.0804\n",
            "Epoch 177/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9748 - loss: 0.0828 - val_accuracy: 0.9769 - val_loss: 0.0798\n",
            "Epoch 178/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9757 - loss: 0.0788 - val_accuracy: 0.9769 - val_loss: 0.0809\n",
            "Epoch 179/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9752 - loss: 0.0785 - val_accuracy: 0.9772 - val_loss: 0.0803\n",
            "Epoch 180/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9759 - loss: 0.0833 - val_accuracy: 0.9777 - val_loss: 0.0803\n",
            "Epoch 181/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9753 - loss: 0.0784 - val_accuracy: 0.9769 - val_loss: 0.0803\n",
            "Epoch 182/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9758 - loss: 0.0769 - val_accuracy: 0.9768 - val_loss: 0.0801\n",
            "Epoch 183/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9770 - loss: 0.0761 - val_accuracy: 0.9771 - val_loss: 0.0795\n",
            "Epoch 184/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9755 - loss: 0.0784 - val_accuracy: 0.9762 - val_loss: 0.0797\n",
            "Epoch 185/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9750 - loss: 0.0774 - val_accuracy: 0.9766 - val_loss: 0.0797\n",
            "Epoch 186/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9761 - loss: 0.0808 - val_accuracy: 0.9777 - val_loss: 0.0796\n",
            "Epoch 187/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9769 - loss: 0.0767 - val_accuracy: 0.9773 - val_loss: 0.0796\n",
            "Epoch 188/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9772 - loss: 0.0754 - val_accuracy: 0.9770 - val_loss: 0.0788\n",
            "Epoch 189/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9768 - loss: 0.0750 - val_accuracy: 0.9775 - val_loss: 0.0796\n",
            "Epoch 190/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9759 - loss: 0.0786 - val_accuracy: 0.9772 - val_loss: 0.0797\n",
            "Epoch 191/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9769 - loss: 0.0739 - val_accuracy: 0.9772 - val_loss: 0.0788\n",
            "Epoch 192/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9754 - loss: 0.0773 - val_accuracy: 0.9774 - val_loss: 0.0799\n",
            "Epoch 193/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9778 - loss: 0.0713 - val_accuracy: 0.9773 - val_loss: 0.0793\n",
            "Epoch 194/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9763 - loss: 0.0729 - val_accuracy: 0.9775 - val_loss: 0.0789\n",
            "Epoch 195/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9785 - loss: 0.0708 - val_accuracy: 0.9778 - val_loss: 0.0788\n",
            "Epoch 196/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9763 - loss: 0.0757 - val_accuracy: 0.9774 - val_loss: 0.0789\n",
            "Epoch 197/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9759 - loss: 0.0757 - val_accuracy: 0.9778 - val_loss: 0.0786\n",
            "Epoch 198/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9763 - loss: 0.0762 - val_accuracy: 0.9774 - val_loss: 0.0794\n",
            "Epoch 199/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0732 - val_accuracy: 0.9781 - val_loss: 0.0787\n",
            "Epoch 200/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9773 - loss: 0.0745 - val_accuracy: 0.9775 - val_loss: 0.0780\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9746 - loss: 0.0857\n",
            "Test accuracy: 0.9775000214576721\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling the model.\n",
        "model.compile(optimizer='RMSProp',\n",
        "              loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "J4hZmRp3kC6y"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling the model.\n",
        "model.compile(optimizer='Adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "CFTvX2Bnmg7y"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iN6JirKYmxIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis"
      ],
      "metadata": {
        "id": "EB55Pcuqmy23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models, preprocessing\n",
        "import tensorflow_datasets as tfds\n",
        "max_len = 200\n",
        "n_words = 10000\n",
        "dim_embedding = 256\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE = 500\n",
        "def load_data():\n",
        "    # Load data.\n",
        "    (X_train, y_train), (X_test, y_test) = datasets.imdb.load_data(num_words=n_words)\n",
        "    # Pad sequences with max_len.\n",
        "    X_train = preprocessing.sequence.pad_sequences(X_train, maxlen=max_len)\n",
        "    X_test = preprocessing.sequence.pad_sequences(X_test, maxlen=max_len)\n",
        "    return (X_train, y_train), (X_test, y_test)\n"
      ],
      "metadata": {
        "id": "81KeBCjOm6J8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "    model = models.Sequential()\n",
        "    # Input: - eEmbedding Layer.\n",
        "    # The model will take as input an integer matrix of size (batch, input_length).\n",
        "    # The model will output dimension (input_length, dim_embedding).\n",
        "    # The largest integer in the input should be no larger\n",
        "    # than n_words (vocabulary size).\n",
        "    model.add(layers.Embedding(n_words,\n",
        "        dim_embedding, input_length=max_len))\n",
        "    model.add(layers.Dropout(0.3))\n",
        "    # Takes the maximum value of either feature vector from each of the n_words features.\n",
        "    model.add(layers.GlobalMaxPooling1D())\n",
        "    model.add(layers.Dense(128, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "TUMEf4Wum8UF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = load_data()\n",
        "model = build_model()\n",
        "model.summary()\n",
        "model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\",\n",
        " metrics = [\"accuracy\"]\n",
        ")\n",
        "score = model.fit(X_train, y_train,\n",
        " epochs = EPOCHS,\n",
        " batch_size = BATCH_SIZE,\n",
        " validation_data = (X_test, y_test)\n",
        ")\n",
        "score = model.evaluate(X_test, y_test, batch_size=BATCH_SIZE)\n",
        "print(\"\\nTest score:\", score[0])\n",
        "print('Test accuracy:', score[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4jz_zeY_nASu",
        "outputId": "a6c81cdc-2586-4542-aa61-dd2f971d2098"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_max_pooling1d                 │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_max_pooling1d                 │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 716ms/step - accuracy: 0.5804 - loss: 0.6797 - val_accuracy: 0.8128 - val_loss: 0.5650\n",
            "Epoch 2/20\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 729ms/step - accuracy: 0.8204 - loss: 0.4678 - val_accuracy: 0.8559 - val_loss: 0.3494\n",
            "Epoch 3/20\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 687ms/step - accuracy: 0.8822 - loss: 0.2915 - val_accuracy: 0.8712 - val_loss: 0.3060\n",
            "Epoch 4/20\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 719ms/step - accuracy: 0.9147 - loss: 0.2193 - val_accuracy: 0.8754 - val_loss: 0.2933\n",
            "Epoch 5/20\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 813ms/step - accuracy: 0.9357 - loss: 0.1799 - val_accuracy: 0.8768 - val_loss: 0.2893\n",
            "Epoch 6/20\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 706ms/step - accuracy: 0.9564 - loss: 0.1317 - val_accuracy: 0.8722 - val_loss: 0.2955\n",
            "Epoch 7/20\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 680ms/step - accuracy: 0.9665 - loss: 0.1089 - val_accuracy: 0.8682 - val_loss: 0.3066\n",
            "Epoch 8/20\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 679ms/step - accuracy: 0.9760 - loss: 0.0843 - val_accuracy: 0.8639 - val_loss: 0.3238\n",
            "Epoch 9/20\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 746ms/step - accuracy: 0.9840 - loss: 0.0639 - val_accuracy: 0.8609 - val_loss: 0.3391\n",
            "Epoch 10/20\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 712ms/step - accuracy: 0.9892 - loss: 0.0469 - val_accuracy: 0.8592 - val_loss: 0.3500\n",
            "Epoch 11/20\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 721ms/step - accuracy: 0.9932 - loss: 0.0343 - val_accuracy: 0.8566 - val_loss: 0.3717\n",
            "Epoch 12/20\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 734ms/step - accuracy: 0.9966 - loss: 0.0233 - val_accuracy: 0.8550 - val_loss: 0.3902\n",
            "Epoch 13/20\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 718ms/step - accuracy: 0.9969 - loss: 0.0196 - val_accuracy: 0.8549 - val_loss: 0.4026\n",
            "Epoch 14/20\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 817ms/step - accuracy: 0.9960 - loss: 0.0182 - val_accuracy: 0.8536 - val_loss: 0.4183\n",
            "Epoch 15/20\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 701ms/step - accuracy: 0.9976 - loss: 0.0135 - val_accuracy: 0.8507 - val_loss: 0.4447\n",
            "Epoch 16/20\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 743ms/step - accuracy: 0.9978 - loss: 0.0112 - val_accuracy: 0.8511 - val_loss: 0.4467\n",
            "Epoch 17/20\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 684ms/step - accuracy: 0.9986 - loss: 0.0083 - val_accuracy: 0.8500 - val_loss: 0.4614\n",
            "Epoch 18/20\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 714ms/step - accuracy: 0.9988 - loss: 0.0076 - val_accuracy: 0.8504 - val_loss: 0.4771\n",
            "Epoch 19/20\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 680ms/step - accuracy: 0.9989 - loss: 0.0071 - val_accuracy: 0.8508 - val_loss: 0.4860\n",
            "Epoch 20/20\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 684ms/step - accuracy: 0.9991 - loss: 0.0054 - val_accuracy: 0.8479 - val_loss: 0.5023\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 104ms/step - accuracy: 0.8503 - loss: 0.4938\n",
            "\n",
            "Test score: 0.5023388862609863\n",
            "Test accuracy: 0.8478800058364868\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K5MdSsJ4nDS1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOKcb99GqrUh+Hh9qoBFePV",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}